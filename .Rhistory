theme_minimal() +
theme_void() +
theme(
plot.title = element_text(size = 14, face = "bold"),
legend.title = element_blank()
)
knitr::opts_chunk$set(message = FALSE, warning = FALSE, include = TRUE,
fig.align = "center",  out.width = "80%")
library(tidyverse)
library(stringr)
library(lubridate)
library(readxl)
library(ggplot2)
library(dplyr)
library(tidyr)
library(viridis)
library(gridExtra)
library(reshape2)
library(gganimate)
library(glue)
library(ggradar)
# Disable scientific notation
options(scipen = 999)
# install.packages("tidytuesdayR")
tuesdata <- tidytuesdayR::tt_load('2023-10-17')
taylor_album_songs <- tuesdata$taylor_album_songs
taylor_all_songs <- tuesdata$taylor_all_songs
taylor_albums <- tuesdata$taylor_albums
glimpse(taylor_album_songs)
glimpse(taylor_all_songs)
glimpse(taylor_albums)
# Checking number of albums in each dataset
taylor_album_songs %>% count(album_name)
taylor_all_songs %>% count(album_name)
# Anti join to check which albums occur in one of the dataset only
anti_join(taylor_all_songs, taylor_album_songs, by = "album_name")
anti_join(taylor_all_songs, taylor_album_songs, by = "album_name") %>% count(album_name)
# album_name Beautiful Eyes, Fearless, Red, and The Taylor Swift Holiday Collection are not in taylor_album_songs
# songs with album_name=NA means that the songs are not in any album
# songs in Beautiful Eyes have a lot of missing data
taylor_album_songs %>% count(track_name) %>% filter(n > 1)
taylor_all_songs %>% count(track_name) %>% filter(n > 1)
# the song appears in Taylor Swift and Beautiful Eyes album but with different years
taylor_all_songs %>% filter(track_name %in% "I'm Only Me When I'm With You")
# Change artist = NA to artist = "Taylor Swift" in taylor_all_songs, for album_name = Beautiful Eyes
taylor_all_songs$artist <- ifelse(taylor_all_songs$album_name == "Beautiful Eyes",
"Taylor Swift", taylor_all_songs$artist)
# Joining by album for taylor_album_songs and taylor_albums
album <- left_join(taylor_album_songs, taylor_albums, by = "album_name") %>%
select(album_name, ep = ep.x, album_release = album_release.x, track_number, track_name,
artist, featuring, bonus_track, single_release, track_release, danceability,
energy, key, loudness, mode, speechiness, acousticness, instrumentalness,
liveness, valence, tempo, time_signature, duration_ms, explicit, key_name,
mode_name, key_mode, metacritic_score, user_score)
glimpse(album)
# Convert track_release to Date format and extract year
album$track_release <- as.Date(album$track_release)
album$year_group <- cut(album$track_release,
breaks = as.Date(c("2005-01-01", "2010-01-01", "2015-01-01", "2020-01-01", "2025-01-01")),
labels = c("2006-2009", "2010-2014", "2015-2019", "2020-2024"))
# Function to calculate correlation coefficient for each year group
get_correlation <- function(album, x, y) {
album %>%
group_by(year_group) %>%
summarize(correlation = round(cor(.data[[x]], .data[[y]], use = "complete.obs"), 2))
}
# Calculate correlation coefficients for energy vs loudness
correlations <- get_correlation(album, "loudness", "energy")
# Merge correlations back into the original data
album <- merge(album, correlations, by = "year_group")
# Create scatter plot with LOESS lines and 95% confidence intervals for energy vs loudness
ggplot(album, aes(x = loudness, y = energy)) +
geom_point() +
geom_smooth(method = "loess", se = TRUE, color = "red") +
facet_wrap(~ year_group) +
# Add correlation coefficient as a text annotation for each year group
geom_text(data = correlations, aes(label = sprintf("r = %.2f", correlation), x = -12, y = 0.9),
inherit.aes = FALSE, size = 3.7, color = "blue") +
labs(title = "Energy vs Loudness by Year Group",
subtitle = "r represents the correlation coefficient between energy and loudness",
x = "Loudness",
y = "Energy",
caption = "The grey band represents the 95% confidence interval around the LOESS trendline.") +
theme_minimal()
# Calculate the percentage of songs by key
key_distribution <- album %>%
group_by(key_name, album_release) %>%
summarize(count = n()) %>%
mutate(percentage = (count / sum(count, na.rm = T)) * 100) %>%
na.omit()
# Define the positions for white and black keys on a piano
white_keys <- c("C", "D", "E", "F", "G", "A", "B")
black_keys <- c("C#", "D#", "F#", "G#", "A#")
# Define positions for keys on the keyboard (x-axis)
key_positions <- data.frame(
key_name = c(white_keys, black_keys),
position = c(1, 2, 3, 4, 5, 6, 7, 1.5, 2.5, 4.5, 5.5, 6.5) # Black keys centered between white keys
)
dfcur <- NULL
for (y in sort(unique(key_distribution$album_release))){
temp = key_distribution %>%
filter(album_release == y) %>%
full_join(key_positions,  by = "key_name") %>%
replace_na(list(count = 0, percentage = 0))
temp$album_release = y
dfcur <- rbind(dfcur, temp)
}
key_distribution <- dfcur
# Create a custom keyboard plot
animated_plot <- ggplot() +
# White keys (rectangles side by side with no gaps)
geom_rect(data = key_distribution %>% filter(key_name %in% white_keys),
aes(xmin = position - 0.5, xmax = position + 0.5,
ymin = -0.3, ymax = 0.8), fill = "#FFFFFF", color = "#000000") +
# Black keys (rectangles centered on top of white keys)
geom_rect(data = key_distribution %>% filter(key_name %in% black_keys),
aes(xmin = position - 0.25, xmax = position + 0.25,
ymin = 0.1, ymax = 0.8), fill = "#000000") +
# Add text labels for white keys with gradient color based on percentage and white text
geom_label(data = key_distribution %>% filter(key_name %in% white_keys),
aes(x = position, y = -0.5,
label = key_name,
fill = percentage), color = "#FFFFFF", size = 6.7) + # White text for contrast
# Add text labels for black keys with gradient color based on percentage and black text
geom_label(data = key_distribution %>% filter(key_name %in% black_keys),
aes(x = position, y = 0.325,
label = key_name,
fill = percentage), color = "#000000", size = 6) + # Black text for contrast
# Use viridis color scale for percentage gradient
scale_fill_viridis_c(option = "plasma", direction = -1) +
# Adjust plot limits and remove axis labels/ticks to resemble a keyboard
scale_y_continuous(limits = c(-2, NA)) +
labs(title = "{closest_state} - Percentage of Songs by Key",
x = NULL,
y = NULL,
fill = "% of Songs") +
theme_void() +   # Remove axis lines and ticks
theme(legend.position="top") +
# Animate over album_release
transition_states(album_release) +
enter_fade() + exit_fly(y_loc = 1)
# Save the animation as a GIF
animate(animated_plot, duration = 10, fps = 1, renderer = av_renderer())
# Aggregate the data by album, calculating the mean for each feature
album_data <- album %>%
group_by(album_name) %>%
select(-c(key,mode)) %>%
summarize(
metacritic = first(metacritic_score),
user_score = first(user_score),
across(danceability:tempo, function(x) mean(x, na.rm = TRUE))
)
# Add Rank based on the average of metacritic and user_score
album_data <- album_data %>%
mutate(
avg_score = (metacritic + user_score*10) / 2,
rank = ntile(avg_score, 10)
) %>%
select(-avg_score, -metacritic, -user_score)
# Normalize loudness, tempo, and instrumentalness
album_data <- album_data %>%
mutate(
loudness = (loudness - min(loudness, na.rm = TRUE)) / (max(loudness, na.rm = TRUE) - min(loudness, na.rm = TRUE)),
tempo = (tempo - min(tempo, na.rm = TRUE)) / (max(tempo, na.rm = TRUE) - min(tempo, na.rm = TRUE)),
instrumentalness = -1/log(instrumentalness + 1e-6),
instrumentalness = (instrumentalness - min(instrumentalness, na.rm = TRUE)) / (max(instrumentalness, na.rm = TRUE) - min(instrumentalness, na.rm = TRUE))
)
# Add max and min rows for scaling in radar chart
max_min <- data.frame(
album_name = c("max", "min"),
danceability = c(1, 0),
energy = c(1, 0),
loudness = c(1, 0),
speechiness = c(1, 0),
acousticness = c(1, 0),
instrumentalness = c(1, 0),
liveness = c(1, 0),
valence = c(1, 0),
tempo = c(1, 0)
)
# Combine max/min rows with album data
album_data <- bind_rows(max_min, album_data)
# Rename album_name to group for compatibility with ggradar
album_data <- album_data %>%
rename(group = album_name)
# Filter top 2 and bottom 2 albums based on rank
top_2 <- album_data %>% slice_min(order_by = rank, n = 2)
bottom_2 <- album_data %>% slice_max(order_by = rank, n = 2)
# Combine the top 2 and bottom 2 albums
selected_albums <- bind_rows(top_2, bottom_2)
# Modify album names to include rank
selected_albums <- selected_albums %>%
mutate(group = paste0(group, " (Rank ", rank, ")"))
# Remove the rank column before plotting
selected_albums <- selected_albums %>% select(-rank)
# Define a color palette for the selected albums
palette_colors <- c("#616161", "#89465180", "#332B2E", "#6aebb4")
# Plot the radar chart for all selected albums in a single chart
ggradar(selected_albums,
axis.label.size = 3,
grid.label.size = 3,
group.point.size = 3,
group.line.width = 1,
background.circle.colour = "white",
axis.line.colour = "gray60",
gridline.min.colour = "gray60",
gridline.mid.colour = "gray60",
gridline.max.colour = "gray60",
group.colours = palette_colors,
plot.legend = TRUE) +
ggtitle("Radar Chart for Taylor Swift's Top 2 and Bottom 2 Albums") +
theme_minimal() +
theme_void() +
theme(
plot.title = element_text(size = 14, face = "bold"),
legend.title = element_blank()
)
glimpse(album)
# Select numeric columns related to audio features (modify as needed)
numeric_features <- album %>%
select(danceability, energy, loudness, speechiness, acousticness, instrumentalness,
liveness, valence, tempo, duration_ms)
# Calculate correlation matrix
cor_matrix <- cor(numeric_features, use = "complete.obs")
# Melt the correlation matrix for ggplot2
melted_cor_matrix <- melt(cor_matrix)
# Plot the heatmap
ggplot(data = melted_cor_matrix, aes(x = Var1, y = Var2, fill = value)) +
geom_tile(color = "white") +
scale_fill_viridis_c(option = "plasma", name = "Correlation") +
labs(title = "Correlation Heatmap of Audio Features",
x = "Features",
y = "Features") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))
knitr::opts_chunk$set(message = FALSE, warning = FALSE, include = TRUE,
fig.align = "center",  out.width = "80%")
library(tidyverse)
library(stringr)
library(lubridate)
library(readxl)
library(ggplot2)
library(dplyr)
library(tidyr)
library(viridis)
library(gridExtra)
library(reshape2)
library(gganimate)
library(glue)
library(ggradar)
# Disable scientific notation
options(scipen = 999)
# Select numeric columns related to audio features (modify as needed)
numeric_features <- album %>%
select(danceability, energy, loudness, speechiness, acousticness, instrumentalness,
liveness, valence, tempo, duration_ms)
# Joining by album for taylor_album_songs and taylor_albums
album <- left_join(taylor_album_songs, taylor_albums, by = "album_name") %>%
select(album_name, ep = ep.x, album_release = album_release.x, track_number, track_name,
artist, featuring, bonus_track, single_release, track_release, danceability,
energy, key, loudness, mode, speechiness, acousticness, instrumentalness,
liveness, valence, tempo, time_signature, duration_ms, explicit, key_name,
mode_name, key_mode, metacritic_score, user_score)
knitr::opts_chunk$set(message = FALSE, warning = FALSE, include = TRUE,
fig.align = "center",  out.width = "80%")
library(tidyverse)
library(stringr)
library(lubridate)
library(readxl)
library(ggplot2)
library(dplyr)
library(tidyr)
library(viridis)
library(gridExtra)
library(reshape2)
library(gganimate)
library(glue)
library(ggradar)
# Disable scientific notation
options(scipen = 999)
# install.packages("tidytuesdayR")
tuesdata <- tidytuesdayR::tt_load('2023-10-17')
taylor_album_songs <- tuesdata$taylor_album_songs
taylor_all_songs <- tuesdata$taylor_all_songs
taylor_albums <- tuesdata$taylor_albums
glimpse(taylor_album_songs)
glimpse(taylor_all_songs)
glimpse(taylor_albums)
# Checking number of albums in each dataset
taylor_album_songs %>% count(album_name)
taylor_all_songs %>% count(album_name)
# Anti join to check which albums occur in one of the dataset only
anti_join(taylor_all_songs, taylor_album_songs, by = "album_name")
anti_join(taylor_all_songs, taylor_album_songs, by = "album_name") %>% count(album_name)
# album_name Beautiful Eyes, Fearless, Red, and The Taylor Swift Holiday Collection are not in taylor_album_songs
# songs with album_name=NA means that the songs are not in any album
# songs in Beautiful Eyes have a lot of missing data
taylor_album_songs %>% count(track_name) %>% filter(n > 1)
taylor_all_songs %>% count(track_name) %>% filter(n > 1)
# the song appears in Taylor Swift and Beautiful Eyes album but with different years
taylor_all_songs %>% filter(track_name %in% "I'm Only Me When I'm With You")
# Change artist = NA to artist = "Taylor Swift" in taylor_all_songs, for album_name = Beautiful Eyes
taylor_all_songs$artist <- ifelse(taylor_all_songs$album_name == "Beautiful Eyes",
"Taylor Swift", taylor_all_songs$artist)
# Joining by album for taylor_album_songs and taylor_albums
album <- left_join(taylor_album_songs, taylor_albums, by = "album_name") %>%
select(album_name, ep = ep.x, album_release = album_release.x, track_number, track_name,
artist, featuring, bonus_track, single_release, track_release, danceability,
energy, key, loudness, mode, speechiness, acousticness, instrumentalness,
liveness, valence, tempo, time_signature, duration_ms, explicit, key_name,
mode_name, key_mode, metacritic_score, user_score)
glimpse(album)
# Select numeric columns related to audio features (modify as needed)
numeric_features <- album %>%
select(danceability, energy, loudness, speechiness, acousticness, instrumentalness,
liveness, valence, tempo, duration_ms)
# Calculate correlation matrix
cor_matrix <- cor(numeric_features, use = "complete.obs")
# Melt the correlation matrix for ggplot2
melted_cor_matrix <- melt(cor_matrix)
# Plot the heatmap
ggplot(data = melted_cor_matrix, aes(x = Var1, y = Var2, fill = value)) +
geom_tile(color = "white") +
scale_fill_viridis_c(option = "plasma", name = "Correlation") +
labs(title = "Correlation Heatmap of Audio Features",
x = "Features",
y = "Features") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))
# Convert track_release to Date format and extract year
album$track_release <- as.Date(album$track_release)
album$year_group <- cut(album$track_release,
breaks = as.Date(c("2005-01-01", "2010-01-01", "2015-01-01", "2020-01-01", "2025-01-01")),
labels = c("2006-2009", "2010-2014", "2015-2019", "2020-2024"))
# Function to calculate correlation coefficient for each year group
get_correlation <- function(album, x, y) {
album %>%
group_by(year_group) %>%
summarize(correlation = round(cor(.data[[x]], .data[[y]], use = "complete.obs"), 2))
}
# Calculate correlation coefficients for energy vs loudness
correlations <- get_correlation(album, "loudness", "energy")
# Merge correlations back into the original data
album <- merge(album, correlations, by = "year_group")
# Create scatter plot with LOESS lines and 95% confidence intervals for energy vs loudness
ggplot(album, aes(x = loudness, y = energy)) +
geom_point() +
geom_smooth(method = "loess", se = TRUE, color = "red") +
facet_wrap(~ year_group) +
# Add correlation coefficient as a text annotation for each year group
geom_text(data = correlations, aes(label = sprintf("r = %.2f", correlation), x = -12, y = 0.9),
inherit.aes = FALSE, size = 3.7, color = "blue") +
labs(title = "Energy vs Loudness by Year Group",
subtitle = "r represents the correlation coefficient between energy and loudness",
x = "Loudness",
y = "Energy",
caption = "The grey band represents the 95% confidence interval around the LOESS trendline.") +
theme_minimal()
# Calculate the percentage of songs by key
key_distribution <- album %>%
group_by(key_name, album_release) %>%
summarize(count = n()) %>%
mutate(percentage = (count / sum(count, na.rm = T)) * 100) %>%
na.omit()
# Define the positions for white and black keys on a piano
white_keys <- c("C", "D", "E", "F", "G", "A", "B")
black_keys <- c("C#", "D#", "F#", "G#", "A#")
# Define positions for keys on the keyboard (x-axis)
key_positions <- data.frame(
key_name = c(white_keys, black_keys),
position = c(1, 2, 3, 4, 5, 6, 7, 1.5, 2.5, 4.5, 5.5, 6.5) # Black keys centered between white keys
)
dfcur <- NULL
for (y in sort(unique(key_distribution$album_release))){
temp = key_distribution %>%
filter(album_release == y) %>%
full_join(key_positions,  by = "key_name") %>%
replace_na(list(count = 0, percentage = 0))
temp$album_release = y
dfcur <- rbind(dfcur, temp)
}
key_distribution <- dfcur
# Create a custom keyboard plot
animated_plot <- ggplot() +
# White keys (rectangles side by side with no gaps)
geom_rect(data = key_distribution %>% filter(key_name %in% white_keys),
aes(xmin = position - 0.5, xmax = position + 0.5,
ymin = -0.3, ymax = 0.8), fill = "#FFFFFF", color = "#000000") +
# Black keys (rectangles centered on top of white keys)
geom_rect(data = key_distribution %>% filter(key_name %in% black_keys),
aes(xmin = position - 0.25, xmax = position + 0.25,
ymin = 0.1, ymax = 0.8), fill = "#000000") +
# Add text labels for white keys with gradient color based on percentage and white text
geom_label(data = key_distribution %>% filter(key_name %in% white_keys),
aes(x = position, y = -0.5,
label = key_name,
fill = percentage), color = "#FFFFFF", size = 6.7) + # White text for contrast
# Add text labels for black keys with gradient color based on percentage and black text
geom_label(data = key_distribution %>% filter(key_name %in% black_keys),
aes(x = position, y = 0.325,
label = key_name,
fill = percentage), color = "#000000", size = 6) + # Black text for contrast
# Use viridis color scale for percentage gradient
scale_fill_viridis_c(option = "plasma", direction = -1) +
# Adjust plot limits and remove axis labels/ticks to resemble a keyboard
scale_y_continuous(limits = c(-2, NA)) +
labs(title = "{closest_state} - Percentage of Songs by Key",
x = NULL,
y = NULL,
fill = "% of Songs") +
theme_void() +   # Remove axis lines and ticks
theme(legend.position="top") +
# Animate over album_release
transition_states(album_release) +
enter_fade() + exit_fly(y_loc = 1)
# Save the animation as a GIF
animate(animated_plot, duration = 10, fps = 1, renderer = av_renderer())
# Aggregate the data by album, calculating the mean for each feature
album_data <- album %>%
group_by(album_name) %>%
select(-c(key,mode)) %>%
summarize(
metacritic = first(metacritic_score),
user_score = first(user_score),
across(danceability:tempo, function(x) mean(x, na.rm = TRUE))
)
# Add Rank based on the average of metacritic and user_score
album_data <- album_data %>%
mutate(
avg_score = (metacritic + user_score*10) / 2,
rank = ntile(avg_score, 10)
) %>%
select(-avg_score, -metacritic, -user_score)
# Normalize loudness, tempo, and instrumentalness
album_data <- album_data %>%
mutate(
loudness = (loudness - min(loudness, na.rm = TRUE)) / (max(loudness, na.rm = TRUE) - min(loudness, na.rm = TRUE)),
tempo = (tempo - min(tempo, na.rm = TRUE)) / (max(tempo, na.rm = TRUE) - min(tempo, na.rm = TRUE)),
instrumentalness = -1/log(instrumentalness + 1e-6),
instrumentalness = (instrumentalness - min(instrumentalness, na.rm = TRUE)) / (max(instrumentalness, na.rm = TRUE) - min(instrumentalness, na.rm = TRUE))
)
# Add max and min rows for scaling in radar chart
max_min <- data.frame(
album_name = c("max", "min"),
danceability = c(1, 0),
energy = c(1, 0),
loudness = c(1, 0),
speechiness = c(1, 0),
acousticness = c(1, 0),
instrumentalness = c(1, 0),
liveness = c(1, 0),
valence = c(1, 0),
tempo = c(1, 0)
)
# Combine max/min rows with album data
album_data <- bind_rows(max_min, album_data)
# Rename album_name to group for compatibility with ggradar
album_data <- album_data %>%
rename(group = album_name)
# Filter top 2 and bottom 2 albums based on rank
top_2 <- album_data %>% slice_min(order_by = rank, n = 2)
bottom_2 <- album_data %>% slice_max(order_by = rank, n = 2)
# Combine the top 2 and bottom 2 albums
selected_albums <- bind_rows(top_2, bottom_2)
# Modify album names to include rank
selected_albums <- selected_albums %>%
mutate(group = paste0(group, " (Rank ", rank, ")"))
# Remove the rank column before plotting
selected_albums <- selected_albums %>% select(-rank)
# Define a color palette for the selected albums
palette_colors <- c("#616161", "#89465180", "#332B2E", "#6aebb4")
# Plot the radar chart for all selected albums in a single chart
ggradar(selected_albums,
axis.label.size = 3,
grid.label.size = 3,
group.point.size = 3,
group.line.width = 1,
background.circle.colour = "white",
axis.line.colour = "gray60",
gridline.min.colour = "gray60",
gridline.mid.colour = "gray60",
gridline.max.colour = "gray60",
group.colours = palette_colors,
plot.legend = TRUE) +
ggtitle("Radar Chart for Taylor Swift's Top 2 and Bottom 2 Albums") +
theme_minimal() +
theme_void() +
theme(
plot.title = element_text(size = 14, face = "bold"),
legend.title = element_blank()
)
# Select only numerical features for correlation analysis
numeric_features <- album %>%
select(danceability, energy, loudness, speechiness, acousticness, instrumentalness,
liveness, valence, tempo)
# Compute the correlation matrix
cor_matrix <- cor(numeric_features, use = "complete.obs")
# Melt the correlation matrix into long format for ggplot2
melted_cor_matrix <- melt(cor_matrix)
# Create a heatmap using ggplot2 with a red-blue color palette
ggplot(melted_cor_matrix, aes(x = Var1, y = Var2, fill = value)) +
geom_tile(color = "white") +
scale_fill_gradient2(low = "red", mid = "white", high = "blue",
midpoint = 0, limit = c(-1, 1),
space = "Lab", name="Correlation") +  # Red for negative, blue for positive
geom_text(aes(label = round(value, 2)), color = "white", size = 3) +  # Add correlation values as text
labs(title = "Heatmap of Feature Correlations",
x = "Features",
y = "Features",
fill = "Correlation") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))
